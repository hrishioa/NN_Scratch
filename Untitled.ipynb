{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class RBM:\n",
    "  \n",
    "  def __init__(self, num_visible, num_hidden, learning_rate = 0.1):\n",
    "    self.num_hidden = num_hidden\n",
    "    self.num_visible = num_visible\n",
    "    self.learning_rate = learning_rate\n",
    "\n",
    "    # Initialize a weight matrix, of dimensions (num_visible x num_hidden), using\n",
    "    # a Gaussian distribution with mean 0 and standard deviation 0.1.\n",
    "    self.weights = 0.1 * np.random.randn(self.num_visible, self.num_hidden)    \n",
    "    # Insert weights for the bias units into the first row and first column.\n",
    "    self.weights = np.insert(self.weights, 0, 0, axis = 0)\n",
    "    self.weights = np.insert(self.weights, 0, 0, axis = 1)\n",
    "\n",
    "  def train(self, data, max_epochs = 1000):\n",
    "    \"\"\"\n",
    "    Train the machine.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row is a training example consisting of the states of visible units.    \n",
    "    \"\"\"\n",
    "\n",
    "    num_examples = data.shape[0]\n",
    "\n",
    "    # Insert bias units of 1 into the first column.\n",
    "    data = np.insert(data, 0, 1, axis = 1)\n",
    "    errors = []\n",
    "    for epoch in tqdm(range(max_epochs)):      \n",
    "      # Clamp to the data and sample from the hidden units. \n",
    "      # (This is the \"positive CD phase\", aka the reality phase.)\n",
    "      pos_hidden_activations = np.dot(data, self.weights)      \n",
    "      pos_hidden_probs = self._logistic(pos_hidden_activations)\n",
    "      pos_hidden_states = pos_hidden_probs > np.random.rand(num_examples, self.num_hidden + 1)\n",
    "      # Note that we're using the activation *probabilities* of the hidden states, not the hidden states       \n",
    "      # themselves, when computing associations. We could also use the states; see section 3 of Hinton's \n",
    "      # \"A Practical Guide to Training Restricted Boltzmann Machines\" for more.\n",
    "      pos_associations = np.dot(data.T, pos_hidden_probs)\n",
    "\n",
    "      # Reconstruct the visible units and sample again from the hidden units.\n",
    "      # (This is the \"negative CD phase\", aka the daydreaming phase.)\n",
    "      neg_visible_activations = np.dot(pos_hidden_states, self.weights.T)\n",
    "      neg_visible_probs = self._logistic(neg_visible_activations)\n",
    "      neg_visible_probs[:,0] = 1 # Fix the bias unit.\n",
    "      neg_hidden_activations = np.dot(neg_visible_probs, self.weights)\n",
    "      neg_hidden_probs = self._logistic(neg_hidden_activations)\n",
    "      # Note, again, that we're using the activation *probabilities* when computing associations, not the states \n",
    "      # themselves.\n",
    "      neg_associations = np.dot(neg_visible_probs.T, neg_hidden_probs)\n",
    "\n",
    "      # Update weights.\n",
    "      self.weights += self.learning_rate * ((pos_associations - neg_associations) / num_examples)\n",
    "\n",
    "      error = np.sum((data - neg_visible_probs) ** 2)\n",
    "#       print(\"Epoch %s: error is %s\" % (epoch, error))\n",
    "      errors.append(error)\n",
    "    return errors\n",
    "\n",
    "  def run_visible(self, data):\n",
    "    \"\"\"\n",
    "    Assuming the RBM has been trained (so that weights for the network have been learned),\n",
    "    run the network on a set of visible units, to get a sample of the hidden units.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row consists of the states of the visible units.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hidden_states: A matrix where each row consists of the hidden units activated from the visible\n",
    "    units in the data matrix passed in.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_examples = data.shape[0]\n",
    "    \n",
    "    # Create a matrix, where each row is to be the hidden units (plus a bias unit)\n",
    "    # sampled from a training example.\n",
    "    hidden_states = np.ones((num_examples, self.num_hidden + 1))\n",
    "    \n",
    "    # Insert bias units of 1 into the first column of data.\n",
    "    data = np.insert(data, 0, 1, axis = 1)\n",
    "\n",
    "    # Calculate the activations of the hidden units.\n",
    "    hidden_activations = np.dot(data, self.weights)\n",
    "    # Calculate the probabilities of turning the hidden units on.\n",
    "    hidden_probs = self._logistic(hidden_activations)\n",
    "    # Turn the hidden units on with their specified probabilities.\n",
    "    hidden_states[:,:] = hidden_probs > np.random.rand(num_examples, self.num_hidden + 1)\n",
    "    # Always fix the bias unit to 1.\n",
    "    # hidden_states[:,0] = 1\n",
    "  \n",
    "    # Ignore the bias units.\n",
    "    hidden_states = hidden_states[:,1:]\n",
    "    return hidden_states\n",
    "    \n",
    "  # TODO: Remove the code duplication between this method and `run_visible`?\n",
    "  def run_hidden(self, data):\n",
    "    \"\"\"\n",
    "    Assuming the RBM has been trained (so that weights for the network have been learned),\n",
    "    run the network on a set of hidden units, to get a sample of the visible units.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row consists of the states of the hidden units.\n",
    "    Returns\n",
    "    -------\n",
    "    visible_states: A matrix where each row consists of the visible units activated from the hidden\n",
    "    units in the data matrix passed in.\n",
    "    \"\"\"\n",
    "\n",
    "    num_examples = data.shape[0]\n",
    "\n",
    "    # Create a matrix, where each row is to be the visible units (plus a bias unit)\n",
    "    # sampled from a training example.\n",
    "    visible_states = np.ones((num_examples, self.num_visible + 1))\n",
    "\n",
    "    # Insert bias units of 1 into the first column of data.\n",
    "    data = np.insert(data, 0, 1, axis = 1)\n",
    "\n",
    "    # Calculate the activations of the visible units.\n",
    "    visible_activations = np.dot(data, self.weights.T)\n",
    "    # Calculate the probabilities of turning the visible units on.\n",
    "    visible_probs = self._logistic(visible_activations)\n",
    "    # Turn the visible units on with their specified probabilities.\n",
    "    visible_states[:,:] = visible_probs > np.random.rand(num_examples, self.num_visible + 1)\n",
    "    # Always fix the bias unit to 1.\n",
    "    # visible_states[:,0] = 1\n",
    "\n",
    "    # Ignore the bias units.\n",
    "    visible_states = visible_states[:,1:]\n",
    "    return visible_states\n",
    "    \n",
    "  def daydream(self, num_samples):\n",
    "    \"\"\"\n",
    "    Randomly initialize the visible units once, and start running alternating Gibbs sampling steps\n",
    "    (where each step consists of updating all the hidden units, and then updating all of the visible units),\n",
    "    taking a sample of the visible units at each step.\n",
    "    Note that we only initialize the network *once*, so these samples are correlated.\n",
    "    Returns\n",
    "    -------\n",
    "    samples: A matrix, where each row is a sample of the visible units produced while the network was\n",
    "    daydreaming.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a matrix, where each row is to be a sample of of the visible units \n",
    "    # (with an extra bias unit), initialized to all ones.\n",
    "    samples = np.ones((num_samples, self.num_visible + 1))\n",
    "\n",
    "    # Take the first sample from a uniform distribution.\n",
    "    samples[0,1:] = np.random.rand(self.num_visible)\n",
    "\n",
    "    # Start the alternating Gibbs sampling.\n",
    "    # Note that we keep the hidden units binary states, but leave the\n",
    "    # visible units as real probabilities. See section 3 of Hinton's\n",
    "    # \"A Practical Guide to Training Restricted Boltzmann Machines\"\n",
    "    # for more on why.\n",
    "    for i in range(1, num_samples):\n",
    "      visible = samples[i-1,:]\n",
    "\n",
    "      # Calculate the activations of the hidden units.\n",
    "      hidden_activations = np.dot(visible, self.weights)      \n",
    "      # Calculate the probabilities of turning the hidden units on.\n",
    "      hidden_probs = self._logistic(hidden_activations)\n",
    "      # Turn the hidden units on with their specified probabilities.\n",
    "      hidden_states = hidden_probs > np.random.rand(self.num_hidden + 1)\n",
    "      # Always fix the bias unit to 1.\n",
    "      hidden_states[0] = 1\n",
    "\n",
    "      # Recalculate the probabilities that the visible units are on.\n",
    "      visible_activations = np.dot(hidden_states, self.weights.T)\n",
    "      visible_probs = self._logistic(visible_activations)\n",
    "      visible_states = visible_probs > np.random.rand(self.num_visible + 1)\n",
    "      samples[i,:] = visible_states\n",
    "\n",
    "    # Ignore the bias units (the first column), since they're always set to 1.\n",
    "    return samples[:,1:]        \n",
    "      \n",
    "  def _logistic(self, x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 9321.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67047102  0.65863655  0.22708573]\n",
      " [ 7.61796688 -3.00183665 -1.86442431]\n",
      " [ 4.24651706 -6.62717855 -6.2025197 ]\n",
      " [ 4.71134486  3.47635449  3.5385775 ]\n",
      " [-7.87648221  3.19906782  1.84519476]\n",
      " [-5.82269101  0.61959499  0.07627871]\n",
      " [-4.89409751 -3.0910659  -3.55863022]]\n",
      "[[ 1.  1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm0FNWdB/Dvj+WhoBhAxQURxQmox0Fl3ILRh4oanSF6\nMscYTSRm0EiMmqhRkSSiJ8csRoMzgpqIWxSdhEzcj4LBjqACxofCsIMrgg8ZNgGBx3u/+eN2WdXV\n1d3VXVVd1VXfzzl9qrq6+tbt29W/vnXr1i1RVRARUXp1ijsDREQULQZ6IqKUY6AnIko5BnoiopRj\noCciSjkGeiKilKsY6EVksoi0ish8x7JeIjJNRJaKyEsisle02SQiolr5qdE/BOAs17KbALysqoMA\nzAAwNuyMERFROMTPBVMicjCAZ1X1n/PPlwA4VVVbRWQ/ADlVHRxtVomIqBa1ttHvq6qtAKCqnwDY\nN7wsERFRmMI6GctxFIiIEqpLje9rFZG+jqabtaVWFBH+CRAR1UBVJYx0/NboJf+wPAPgu/n5UQCe\nLvdmVeVDFbfcckvseUjKg2XBsmBZlH+EyU/3yikAXgfwZRH5UEQuBfArACNEZCmA0/PPiYgogSo2\n3ajqRSVeOiPkvBARUQR4ZWwdNTc3x52FxGBZ2FgWNpZFNHz1ow+0ARGNehtERGkjItA6n4wlIqIG\nxUBPRJRyDPRERCnHQE9ElHIM9EREKcdAT0SUcgz0REQpx0BPRJRyDPRERCnHQE9ElHIM9EREKcdA\nT0SUcgz0REQpx0BPRJRyDPRERCnHQE9ElHIM9EREKcdAT0SUcgz0REQpx0BPRJRyDPRERCnHQE9E\nlHIM9EREKcdAT0SUcgz0REQpx0BPRJRyDPRERCnHQE9ElHIM9EREKcdAT0SUcgz0REQpx0BPRJRy\nDPRERCnHQE9ElHKBAr2IjBWRhSIyX0QeF5GmsDJGREThqDnQi8jBAC4DcIyq/jOALgAuDCtjREQU\nji4B3rsZwE4APUSkA0B3AKtDyRUREYWm5hq9qm4AcCeADwF8DGCjqr7ste6qVbVuhYiIgqq5Ri8i\nhwL4MYCDAWwCMFVELlLVKe51x40bj0MOMfPNzc1obm6udbNERKmUy+WQy+UiSVtUtbY3ilwAYISq\nXpZ//h0AJ6jqD13r6dy5iuOOC5xXIqLMEBGoqoSRVpBeN0sBnCgiu4mIADgdwGKvFbt1C7AVIiIK\nJEgb/TsAHgXwFoB3AAiA33ut29ZW61aIiCiomptufG9ARN94Q3HiiZFuhogoVZLSdOPbzp312AoR\nEXmpS6Bn0w0RUXwY6ImIUo6Bnogo5dhGT0SUcqzRExGlXF26VwKKiDdDRJQqDde9EgADPRFRTOoW\n6GfNqteWiIjIqW6Bvr29XlsiIiIn3jOWiCjl2EZPRJRyrNETEaUcAz0RUcqx6YaIKOUY6ImIUo5N\nN0REKccaPRFRyrFGT0SUcgz0REQpx6YbIqKUY6AnIko5Nt0QEaUca/RERCnHQE9ElHIcj56IKOXq\nFuh5g3AionjUPdC3tzPoExHVU90C/QUXAJMmAWPGAPvsE912RIA334wufSKiRlPX7pUPPwzMmwds\n2hRN+q+/bqYrVkSTPhFRI0pNP/pNm4Bhw+LOBRFR8jR0oG9tBaZPN/MdHfHmhYgoqRo60I8dC5x5\nZvHy224D/vVf658fIqIkEo34SiYRUcBs46ijgAULzPKgm125EjjsMDutDRuA3r0L1+FFWkTUqEQE\nqiphpFXXGr0V5AHgs8+CpfXYY8HeT0SUFYECvYjsJSJ/FpHFIrJQRE7w+96ePQuft7ZWu+3q1ici\nyqqgNfq7AbygqocDGAJgca0J7bcfsHSp92uPPgpcdRWwebPpWXPQQQz0RER+1dxGLyI9AcxT1YEV\n1vuijd7NuWnrQqfOnYFjjwW2bAF69DCvDR5c/CcwahTwyCN2Ohs3Ar16lU6fiKiRJKWN/hAA60Tk\nIRFpEZHfi8ju1SQwbZqZWkMiqJogDxReVOVV058/3553B3giIrIFCfRdABwLYKKqHgtgG4Cbqkng\nrLPMtKnJTJ018EmTyr933jx7fuPGarZKRJQtXQK8dxWAj1T1H/nnUwHc6LVir17jsWGD9aw5/zCc\nwd05v3lzgJwRETWYXC6HXC4XSdo1B3pVbRWRj0Tky6q6DMDpABZ5rbtq1fgv2tvddu2y551Xt6oC\n554LDCx7BsDW0uJvPSKiJGpubkZzc/MXz2+99dbQ0g5SoweAqwE8LiJdAbwL4FKvlbp3L53Ae+/Z\n81/5ij2/ZQvwwgv+MzJxYvGy5cvNRVQPPQRcf73/tIiI0qQuV8aqKkaOBJ59NrrtfPnLwLJlxcuH\nDwdeeYU9cIiosSSl101VunaNNn2vIA+YIwMioixr6EHNiIiosro13bz6KnDqqZFuqiw23RBRI2nI\npptTTgHuuKNeWyMiIkvdavT280g3VxJr9ETUSBqyRm8pdSeoQw+tbz6IiLKi7oFeBFi4EBgzBti5\nE/i3fzPLZ8wABg0y8z/9ab1zRUSUXrH0ujniCDOWTdeuwGmnmWUHHwwsWWKaWM4/3ywLs989m26I\nKKti7155zTWFwyAAdjv+0KH1zw8RUdrEHuhFzBj0Tp3yudp/fzMMwsMP1z1bRESpUfdeN37Mnw8M\nGVLc3BKkx05HB+9KRUSNo6F73fjRJehQa0RE9IVEBvrDDwdmzQo3TZ6MJaKsSmTTTem0an9ve7vd\n9k9ElHSpb7op55JL4s4BEVFjabhA77w5CRERVdZQgb5rV+CYY+LOBRFRY2mo/i07d9b+Xp6MJaKs\naqgaPRERVa+hA/3o0XHngIgo+Ro60J9wgv91Z8yILh9EREnWUP3o7TSByy8HJk6s7qbjbKcnokaR\n6X70lqOOMkMlXHZZ3DkhIkq2hg30++9vpoccEm8+iIiSrqG6V1rWrwe+9CUzz+YYIqLyGjLQ9+pl\nzzPQExGV17BNN5Yzz4w7B0REydaQvW6Kt+FvPdb+iahRsNeNy8SJwKhRceeCiCiZUlGjB4A5c4AT\nTyy/Dmv0RNQoWKP3wPvBEhF5Y6AnIkq51AR63iaQiMhbasLj0UdXXuedd6LPBxFR0qTmZKzZVuV1\nVqwABg6MPi9EREHwZGwAn38edw6IiOorcKAXkU4i0iIiz4SRoajt2hV3DoiI6iuMGv01ABaFkE5g\n++xTeZ22tujzQUSUJIECvYj0A3AOgAfCyU4wS5fGnQMiouQJWqP/HYCfAEjENaedO8edAyKi5Kk5\n0IvIuQBaVfVtAJJ/xCptfelnz447B0SUBkHGox8GYKSInANgdwB7isijqnqJe8Xx48d/Md/c3Izm\n5uYAm80GVeCkkzg+D1FW5HI55HK5SNIOpR+9iJwK4DpVHenxWt360X/2GdCzZ/l15s4FjjuuLtkJ\nRNUcoXR0cHgHoixiP/oSunePOwfhY42eiIIK5VaCqvp3AH8PI60g0nQy1grwDPREFFSqavQAsNtu\ncecgXAz0RBRU6gL9zJnlX9+ypT75CAsDPREFlbpA361b+de/+c365CMoNt0QUVhSNXolYMay6dq1\n/DqNEDzb24EuXYAdO4CmprhzQ0T1xl43ZXQJ5fRycjTCnxIRJVvqAn3aMNATUVAM9AnFNnoiCgsD\nfcIx0BNRUJkM9I00Jj0DPREFlclAf0nRsGvJ08hNN7kc7w1AlCSZDPSLEnE/LH8aMdAPHw5cdFHc\nuSAiSyYDPRFRlqQy0DdiLbiUNH0WSq5HHgEGDYo7FxSVVAb6RqMKtLQUL3NOiaI0bRqwbFncuaCo\nMNAnwOLFwNChwIwZxTcZYaAPJpcDPv887lwQxYuBPgGs7p4LFhS/xkAfzPDhwO9/H3cuiOLFQJ9Q\nbLoJT0dH3DkgilcmA30192B9+unK96F1+vTT6vNTDgM9EQWVyUDvdN99wNq1Zr69HVi/vvD1114z\nNx33Y+ZMYN99q89DuWAeNND/+Mf8syDKukwG+nfesefHjDFdywDgN78B+vSxX5s2DbjjDv/puv8k\nwhA0SE+YwKYLoqxLbaCvdPXryy8DF19s5q2mnFWrCtdZuTL8fHnxakoKsxbOGj1RtqU20B94YPnX\nH3kEmDKl/DrVtOVHhUGaqPFddhnw4IPxbT+1gb7SCVSrXT4Ma9dG11c7jEDPPwuieD3wAHDvvfFt\nP7WBvhpBa+59+wLf/37t7/cKxOxeGR+ewKYoxLlPZTbQh32C8uOPw03PEmTn8PqzWLEC2L49WJ7C\n8N//Ddx+e9y58DZhgrnJPFFaZDbQO4NfqRr95s3+0wtyVFDuvWE33fzTPwG33ho8zaB++lNg3Li4\nc0GUDZkN9OVYNd4bb4wvD2E23bjT2LQpeJpEbjt3sskrqTIb6N9/354XARYuBCZNMs8r9dipp7Cb\nbqi8tJXZxo3AnDn28/POMwE5Ct262b8hSpbMBnp3H/l77rHno7jwqZy0BBVKnnHjgBNPtJ8//TTw\nf/8X3fZ4C8lkymygd/rww+J2cq9282efBR591DsN9/pDhwKvvho8b6zRl/bii+F/trSVmddJ5bR8\ntqi9+GK4f1zsdROR557zt96ECUAnHyVx6aXAqFH+0mxpMUMoVMP5ZxFlG31afuhf+1q410MA6Qv0\n9Zamcvva14DRo+PORThSHejPPdd/z46JEyuvU65LpteoldXu9OX60weRxB9fEvMEJCvQb9hgBtoL\nW5SfLQnlRsVSHegB4Be/CC+tcjuxc6A0P+sDwPLlwAsvRNe9Mus/umqPqIDaymz06Gh6MvXubQba\nayRZ3+eSKvWBPkxWjX733f2tX2mnv+IKc9RhrZempptK1xXUYxyhs86y5195BfjlL/2/t5oymjwZ\neOst/+tXwz3QXhhYo8+eTAT6YcPCScfaia1+9ocdBvzlL5XXL8VPsAsr0O/YUf14PJs2AX/7W+3b\nDPK6e922ttrb4996yxzZ3Xyzv21Vmz8iP3gyNmK33RZOOu42+pUrywfCSl/shg2lX5s82V8alkMP\nLR7awBm0Ro40V8W603ReT+D2m98AZ5zhb/tR6tQJaGoyYwq5+RlK+vHH/W+r1kAf1Y940iRg6tRo\n0o4C/yCTqeZALyL9RGSGiCwUkQUicnWYGQtT587hpFNpJy4VaEtpaSn92rXXFqbhro1v3WqaIwBg\nyBDgvffMxTGlLFjgPR7PIYeU/sOp9kf7yivAV79q5us1xPMf/xhuekkMVGFfoc2mm+wJUqPfBeBa\nVT0SwEkArhSRweFkK3m2bTMPy8svm6lzx3af+A1rp58+HejevXDZPfcAp51m5ufPL/9+1fKBt9QA\nXtXm/7nngFmzqntvpbzHhQGL0qTmQK+qn6jq2/n5LQAWA0jQ4AG2MEYi7NGj8PmECWbqDAjunhde\nweKjj0p30yzVvdLrhJxXGqVOuo4bB6xe7b1NILzadzXpWOuee244265We7u5qM0taU03UWiEGv0T\nTwD9+oWTFoXURi8iAwAcDWBO+TXjMWhQ4b1gw/D885XX8drp+/cHHnvMe/0lS7zT8ArgXt05r70W\n2LKleLl7/BF3eqUCdKUf7Y4dtf9J1BoQOjpME5Xz6KoWO3d6N53xZGwy5HLhD/29Y0fwcX7a280V\ns4A9lER7e+Hvrr3d3zDoLS3RDW/uFjjQi8geAKYCuCZfsy8yfvz4Lx65XC7oJqvWrx+wbl3dNwtV\n84fgDkql2sStoHnqqfaO4hVw3n7bjOfu9uSThX8AfoPV3nvb89Onl2/rd3L/aJxB3/0H8Oab/vNz\nwQWlx8z/2c+AXr2Kj7DCUmuAr+V927YBI0YULnvmGeDsswuXvftu7b2fnNy3stuxI7ohJIJy7j9b\nt5qB2UpdPLZtG3DTTZXT3G03M/DaGWcU9+Daf3+zzRUrTDOp1RnC7e9/N1fMAuZ38/rr5or5Pfe0\n1zniCOCii4rf6y6boUNNbBo0yDzP5XIFsTJUqlrzA0AXAC/CBPlS62hS2PXj8B6XX27PH3SQmVrb\n+tGPzPS++wrzMGFCYX7mzTPTK68sTn/xYtXJk+10Fy5UnT3bft39uV57zd7W9u3eeb7ssuIy8Xp+\nww2Fr7mtWVP4+vXX2+8/9tjisl+40H4+cKBZ1q+f9/e0bJm/7+373y+dP+d6p51WmNdt27w/25Yt\nZvmGDaXT3bZNtb29cDvTppVe3zJrluq6dfbzE04w7+3osJd9+9tm2RVXFOd/9eriNIcOVX3lFVO2\nc+eaZdOnq77/vpm39k8rn4B57fnnzfxNN5nXLrqoOC9On36qOn68av/+hcs3bTLT1lbz/tGj7de2\nbjXTjRtN3tvbVadOLU77pZfs34uq6nnnee+H1vPHHiv87mbNKr+fWpzl+dJL3q/94Q9m2qWLmZ58\ncuF606cXludzz6nutlvxb8hdToDq0UeXzo93fqEaID47H0Fr9A8CWKSqdwdMp2FpmRqM9Zp7nY6O\nwkM9q2bsNd7Op58WHgEceSSwbFnpbdarb/6f/mRqQdVs2+tcyZo1Zrpokblhu8Xvpf/33+9vvUpE\nTFfTUt+ZU/fupieXs2uqnzI9+WTghhvs59bwwR99VLzuffcVPt+2DTjggOL13noLGD7c7BfHH2+W\njRgBjBlTPi/f/KaZ/upXhcuHDAGuusocNTm/z8svB8aPNwMAPvWU/dpee5nPPny4eb5jh5muXGmO\nuu65xwyNfMAB5krwf//34ry89pqZWue9nnqq8HX30Z37BH6YPbystGptzkyqIN0rhwG4GMBpIjJP\nRFpE5OxK70ubcgGpVPPLL39ZeKi3dauZegX6U04Brr++cNkll5TeprO7Yamdct264hO8HR3F4/CX\n26mtQFGK3x9fe7sZFvpnPwO++93C5VHZsgW45RYzv3q1aRoBzGG7V6Bftw743veKy8NZhnPm1P4n\n6yd4hFkeqqXzumCBCbTu5jtnM92TT9rpWFOrMmL9mVvv/+tfgdZWM19qm9UG6jACe6kyj7JbcJx/\nEkF63bymqp1V9WhVPUZVj1XVF8PMXNgGDAg/zddft+etH6O1Yy9aZKbuL9g9AFqlWkQ17r3X1JLv\nv9+7BgiYH/JBBxUua2sr3zPHD68hHAD7HIW17O67Cy90amuzr3WwyqyawDZunFn/uuuAiy+uvP70\n6cAdd5j5Aw8EBg408yNGAIcfbub79AGuvNLM/+1vwEMPFffZd35Gr5PjXmr9sfsZXdXvdirlodJ+\n6P4zdJ54tOajDJh+hhSvpFKgr6ZGX69rRoLIxJWxFmdQDouzp4wVKP/0JzO1glWlS/etKx9rubDr\npJOKl/Xvb8bRKXflrR/WTr12bXHzgjuoixTWcFta7Nqd+8rO//zPwufNzXYgO/JIM60m0N9+u/lj\ne/BBYMoUcx8AqwnBS7kfprMXhLu3ktXMlAblysDrNa8/cecRq/W69ZrXifmwavRJ0wj5z1Sg99Pl\nKQxW260VaG+9tXywt4ZIvvPO6rc1e3bxMr/XDThrJ147629/a6Z9+5o/DyevH757OAXryl2v7Tkt\nWQJ06eJv3VLWry/steRs74+KM49+81uvw/egtfZyrN+Re+qeL+fZZ+39NGjTTZg1+kpp+q3RJ60t\nn4E+AnfdZabOw3mvcVqq5dVHPohaAlWldJzctbxy23A3ffzHfxSfm6iUB+cPrtwRQZQ1sE2bCj/n\nrl2FN80uVwbt7aXzbeW5rc1fWuX6i7e1ld+X3OWzYUNxd0fn9lXt9KwKjXN962jQ+RlGjjRNaO5u\nz5s3Fz5ftw745BPv/K1aZcrXT9dpv82S7rwCpgLz4YfmvIN1otj67M67yFnneixLl5r3Oa1dCyxe\nDHz2WfG2V60yXacjEVb3nVIP+On3VCcffFDYpanRHlY3srAebW32/IIFha99/HHx+gsXqo4dq/qL\nXxQuv/lm7/QPPlh18ODCZX36xFN2VvfKVauqe5+q6RbnfG7N53L28/PPt5cPHWrvc01NZtnVVxem\n+5e/2PNWV8hy+bC6Ylrb+sY3SufXOW91r5w7t/B7cb/H6l4JqA4YUJzeKacUb2vr1sKp9Xj1VdW3\n3zbz1ucHVFesMNOLLzbTffc103POsdfp3r3y9zFunP38rrvs+ZkzvX/3771XnM7zzxeu437d6jLZ\no4d3Pn7yE+/lmzebaf/+xWU4ZIhqz55m/swzy39v5jlUNZw43KXC/0CqdOsWdw6COfnkcNNzDtkw\ncmTha+efX7z+VVcBM2YUL7/9du/0P/igeFnQG1P37Wuf7K5FLUMdl6plqXovd45Nb9Ws3eeHgozx\n89e/Vv8eZ43W63upxOsIoVSvsvXrgZ49S79v4UIztb4L57mkaq94Xr7cni9Vs692eG7ArtFbRy9u\npa5orXRuyTpiqff5nkw13fTtW3wYmGXOndL9Y/Vq3ojj6mK3anufuEXVbFMq6Jd6vdL6YatlHKJK\ny6zP4PVZyqUR5md3pqXqf5iDar+vWvJjWbw4vPRrlakaPRBOW3la/OhH9ryfQNQIvQsqCfMzVPNj\nDRrog55fChrovfJrVRT8nvy30vXbFdXLG28U5s9ZLqpmmAPn81IqlX+pITgslU7WOtM/4ojiZZXy\nFvYfQaZq9Jaw7jjV6J54wp73s2MlIdDXmgdriKUwP4M1TDRQXH6jRhX2iKpXjb5UgKrmcztPKrqv\nt3CygqzXuEvVbK+asnj++dKBvpaLyjo6Kgd1L6VuZmN9Fq+rnZ2f02q+ssxxDAfZqVPhH1YYMhno\n633Y1Ij8Hr7XW615iOpCHusq0TfeKFz+6KPAN75hP3f3yIhKqfMltX7ucvestX5H7jbwdeu8g26p\nG6i7e9qUs3Wr6ZrpzgNgBsPzYtWonVTNUCKdO/u/B7QftcaWhx4qfN7WFjwvTpkM9H6unsyaRqnR\nB+VV0yrnuuvKv/6tb5mp10le5wnQcvcqCLPi4dVtz49SQdjidb3Gr39tpv/zP4XLR4/2vhH7Mcd4\np21dDe3H3LmFJ8eDNGnVeg/icsp9l+XyGnXlM5OB/gc/MAVbalz4RuccR8cv907oFdTfe6+2/CRJ\ntTc6sa6JCJvzh12u1uy1vt/1vv1tOyhW+pP2c38FN2sYiZkzi18LOpxGKWE1ganWv+LCQB+TtNbs\na6nV+RkuIeiQCmFIw1EFUPij/+pXS3fjs/zjH9Wn+/jjpgYMpKfc3AGx1hp9VIG+1hPADPQRs27C\nnXXu/stJDQxRjmrpxw9+EE467uGB99gjnHSTcv4pqnyEFeiB+gd61uhjdOedwM9/Hncuksd9cjEp\n4h5Y7N57491+rer9x530QB9HjZ6BPma33lrYQ4KoUZUKGGkN9EG2E0WZ1BrMGejrZOpUc1XdH/4Q\nd06Ialcq0NQ70EfVxBbmydgolAv0rNEnRFOT6Rqm2riH6JRtSanRRzVSLJtuasNAX8IVV9h3HiKi\n6tTrpHnSTsay6aYBzZ5tbnrcq1fh8jVrzElc649gr73qnzciL0mp0der6SZIjT7oAHle2HTTgPbe\n2wzLu369uXH0f/2XWb7ffqZb5ooV5vlxx5VP5+tfjzafRJaktNH7HeisWtUE+krBM4oyKfcHx0Df\nAAYOBH74w+Iv8vbbzc2prYuvnJd5DxlipqVua5eUPs+UHkmp0UcV6N3BMsgFSvUO9HH+3jM3THFQ\n7sO9sWPNtLkZePhhs/P8+c/AAQeYXjxLlhQ37bS31++2hpQtaQ/01fS66ego3TwTR6CPs0bPQB8i\n6wbXF15oLxsxwkyd41SL2Dvgzp1AS4uZHngg8L//awbeWrXKDFU6bJi5O9GAAWboW6fRo4EHHoj0\nI1GDScpRYlSB3q3WNnEgWTV6BvqUce9cXbsCJ5xgPz/00OL3nHGGmV5ySfFr991ndq6tW82fxbZt\ndhqnnFJ482JKvwcf9F7uHDvfLYreZe6bYofFPbBeuSulN24sHey3b69tHPpKyv25xNmsIxrxFkRE\no94GhWfnTnO0sXatGbp2r73Mj/akk4A+fYAJE4B588xrffqYH4sIMGUKcNttZnrOOWY0xCOPBO6/\nvzD944+3B9oCzHmMzz831zDs3GnGCCciABCoaijHHQz05IsIMGYMMGlS3DmJzuefe9+EYsMGoHdv\n4DvfMTcUqZZ77HnrIWJP29vNtKPD3AxD1czPnAmcfnrh+jt2mD/jrVvNEeHuu5vn8+aZfPbrZ7bV\n3m7+sFtbgcMPN3+kPXqY91jvnTXLNC+OGmWuCre2LWLny+qK6Gzz7ugwr3XpYppprGbLzp3t16z3\nWGm0t5u8NzWZst6xwywfMAA4+2xTiRg82KSzcqXJ465ddr733NOkYVUMrBq79f2sXQt062aW9ehh\nKiFr1gCHHWZuqH766Wab1gByd91l7ifQqZN53+rVwP77m/dt3mzKrHNnk4+mJjMq7OOPmxuZfOUr\n5gbvmzaZI/KmJnPj+z59TD569zZNsJ06mflu3czn2L4d2LLFpL9mjem8sc8+Js+ffGJ/t+vWAePG\nMdBTnX36KdCzp9lhs0gE+N73gMmT485J+ETM/YN/97v4tn/FFeZq9LPOAqZNS865hjiJhBfo2UZP\nvuyzT9w5iNfPfw6cf37cuYhGU5NpmouT1RWZV6NHgzV6IorVrl2miUTE3Ct1+/ba7pKWNmHW6Bno\niYgSKMxAzytjiYhSjoGeiCjlGOiJiFKOgZ6IKOUY6ImIUi5QoBeRs0VkiYgsE5Ebw8oUERGFp+ZA\nLyKdANwD4CwARwL4logMDitjaZTL5eLOQmKwLGwsCxvLIhpBavTHA1iuqh+oahuAJwHwXkplcCe2\nsSxsLAsbyyIaQQL9gQA+cjxflV9GREQJwpOxREQpV/MQCCJyIoDxqnp2/vlNAFRVf+1aj+MfEBHV\nIPaxbkSkM4ClAE4HsAbAXADfUtXFYWSMiIjCUfMwxaraLiI/BDANpgloMoM8EVHyRD56JRERxSuy\nk7FZuJhKRCaLSKuIzHcs6yUi00RkqYi8JCJ7OV4bKyLLRWSxiJzpWH6siMzPl9WEen+OMIhIPxGZ\nISILRWSPrrtxAAADNUlEQVSBiFydX5658hCRbiIyR0Tm5cvj9vzyzJUFYK65EZEWEXkm/zyT5QAA\nIvK+iLyT3zfm5pdFXx6qGvoD5g9kBYCDAXQF8DaAwVFsK84HgJMBHA1gvmPZrwHckJ+/EcCv8vNH\nAJgH01w2IF8+1hHVHADH5edfAHBW3J+thrLYD8DR+fk9YM7fDM5weXTPTzsDmA1gWIbL4scAHgPw\nTP55Jsshn/d3AfRyLYu8PKKq0WfiYipVnQVgg2vx1wE8kp9/BMB5+fmRAJ5U1V2q+j6A5QCOF5H9\nAOypqm/m13vU8Z6GoaqfqOrb+fktABYD6Ifslse2/Gw3mIrPBmSwLESkH4BzADzgWJy5cnAQFLek\nRF4eUQX6LF9Mta+qtgIm+AHYN7/cXSYf55cdCFM+loYvKxEZAHOkMxtA3yyWR765Yh6ATwDkVHUR\nslkWvwPwEwDOk4FZLAeLApguIm+KyOj8ssjLgzcHj16mznaLyB4ApgK4RlW3eFxHkYnyUNUOAMeI\nSE8AL4lIM4o/e6rLQkTOBdCqqm/nP38pqS4Hl2GqukZE9gEwTUSWog77RVQ1+o8B9Hc875dflgWt\nItIXAPKHWGvzyz8GcJBjPatMSi1vOCLSBSbI/1FVn84vzmx5AICqboZpQ/0XZK8shgEYKSLvAngC\nwGki8kcAn2SsHL6gqmvy008BPAXTzB35fhFVoH8TwGEicrCINAG4EMAzEW0rbpJ/WJ4B8N38/CgA\nTzuWXygiTSJyCIDDAMzNH6ptEpHjRUQAXOJ4T6N5EMAiVb3bsSxz5SEie1s9J0RkdwAjYE6qZaos\nVPVmVe2vqofCxIAZqvodAM8iQ+VgEZHu+SNeiEgPAGcCWIB67BcRnl0+G6bnxXIAN8V9tjuizzgF\nwGoAOwB8COBSAL0AvJz/7NMAfMmx/liYM+eLAZzpWD40/4UvB3B33J+rxrIYBqAdpofVPAAt+X2g\nd9bKA8BR+c8/D8A7AK7PL89cWTg+x6mwe91kshwAHOL4fSyw4mI9yoMXTBERpRxHryQiSjkGeiKi\nlGOgJyJKOQZ6IqKUY6AnIko5BnoiopRjoCciSjkGeiKilPt/ZsbeqbHjlWsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bd75950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = RBM(num_visible = 6, num_hidden = 2)\n",
    "training_data = np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,1,1,1,0], [0,0,1,1,0,0],[0,0,1,1,1,0]])\n",
    "plot(r.train(training_data, max_epochs = 5000))\n",
    "print(r.weights)\n",
    "user = np.array([[0,0,0,1,1,0]])\n",
    "print(r.run_visible(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
